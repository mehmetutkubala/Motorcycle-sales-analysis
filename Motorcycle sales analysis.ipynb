{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a930fe",
   "metadata": {},
   "source": [
    "# Motorcycle sales analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2407606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\",100)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2194e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"sales_data.csv\") #https://www.kaggle.com/datasets/devijeganath/motorcycle-sales-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a7b60",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "100d081d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse</th>\n",
       "      <th>client_type</th>\n",
       "      <th>product_line</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>total</th>\n",
       "      <th>payment</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16.85</td>\n",
       "      <td>134.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19.29</td>\n",
       "      <td>173.61</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32.93</td>\n",
       "      <td>263.45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>37.84</td>\n",
       "      <td>605.44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>60.48</td>\n",
       "      <td>120.96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>32.87</td>\n",
       "      <td>295.83</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>10.03</td>\n",
       "      <td>320.96</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>32.80</td>\n",
       "      <td>393.64</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>48.25</td>\n",
       "      <td>241.23</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>27.41</td>\n",
       "      <td>548.13</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     warehouse  client_type  product_line  quantity  unit_price   total  \\\n",
       "0            0            0             4         8       16.85  134.83   \n",
       "1            1            0             0         9       19.29  173.61   \n",
       "2            1            0             1         8       32.93  263.45   \n",
       "3            1            1             3        16       37.84  605.44   \n",
       "4            0            0             5         2       60.48  120.96   \n",
       "..         ...          ...           ...       ...         ...     ...   \n",
       "995          0            0             2         9       32.87  295.83   \n",
       "996          2            1             0        32       10.03  320.96   \n",
       "997          2            1             2        12       32.80  393.64   \n",
       "998          1            0             3         5       48.25  241.23   \n",
       "999          1            1             2        20       27.41  548.13   \n",
       "\n",
       "     payment  day  month  year  \n",
       "0          0    1      6  2021  \n",
       "1          2    1      6  2021  \n",
       "2          0    1      6  2021  \n",
       "3          1    1      6  2021  \n",
       "4          0    1      6  2021  \n",
       "..       ...  ...    ...   ...  \n",
       "995        0   28      8  2021  \n",
       "996        1   28      8  2021  \n",
       "997        1   28      8  2021  \n",
       "998        2   28      8  2021  \n",
       "999        1   28      8  2021  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdba16b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   warehouse     1000 non-null   int32  \n",
      " 1   client_type   1000 non-null   int32  \n",
      " 2   product_line  1000 non-null   int32  \n",
      " 3   quantity      1000 non-null   int64  \n",
      " 4   unit_price    1000 non-null   float64\n",
      " 5   total         1000 non-null   float64\n",
      " 6   payment       1000 non-null   int32  \n",
      " 7   day           1000 non-null   int32  \n",
      " 8   month         1000 non-null   int32  \n",
      " 9   year          1000 non-null   int32  \n",
      "dtypes: float64(2), int32(7), int64(1)\n",
      "memory usage: 50.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec7629b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date            0\n",
       "warehouse       0\n",
       "client_type     0\n",
       "product_line    0\n",
       "quantity        0\n",
       "unit_price      0\n",
       "total           0\n",
       "payment         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #We examine the empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca414f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Breaking system          230\n",
       "Suspension & traction    228\n",
       "Electrical system        193\n",
       "Frame & body             166\n",
       "Miscellaneous            122\n",
       "Engine                    61\n",
       "Name: product_line, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"product_line\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a11c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Retail       775\n",
       "Wholesale    225\n",
       "Name: client_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"client_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f84834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Central    480\n",
       "North      340\n",
       "West       180\n",
       "Name: warehouse, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"warehouse\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f604a5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit card    659\n",
       "Transfer       225\n",
       "Cash           116\n",
       "Name: payment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"payment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece20c0",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d54343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"product_line\"]=df[\"product_line\"].map({\"Breaking system\":0,\"Suspension & traction\":1,\"Electrical system\":2,\"Frame & body\":3,\"Miscellaneous\":4,\"Engine\":5})\n",
    "#We replace the data in product_line with 0, 1, 2, 3, 4 and 5.\n",
    "df['product_line']=df['product_line'].astype(int) #We change the data type of product_line to integer.\n",
    "\n",
    "df[\"client_type\"]=df[\"client_type\"].map({\"Retail\":0,\"Wholesale\":1})\n",
    "df['client_type']=df['client_type'].astype(int)\n",
    "\n",
    "df[\"warehouse\"]=df[\"warehouse\"].map({\"Central\":0,\"North\":1,\"West\":2})\n",
    "df['warehouse']=df['warehouse'].astype(int)\n",
    "\n",
    "df[\"payment\"]=df[\"payment\"].map({\"Credit card\":0,\"Transfer\":1,\"Cash\":2})\n",
    "df['payment']=df['payment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6318bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"]=pd.to_datetime(df[\"date\"])\n",
    "df[\"day\"]=(df[\"date\"]).dt.day\n",
    "df[\"month\"]=(df[\"date\"]).dt.month\n",
    "df[\"year\"]=(df[\"date\"]).dt.year\n",
    "del df[\"date\"]\n",
    "df['day']=df['day'].astype(int)\n",
    "df['month']=df['month'].astype(int)\n",
    "df['year']=df['year'].astype(int)\n",
    "#We divide date into day, month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c48716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total           1.000000\n",
       "quantity        0.870207\n",
       "client_type     0.656483\n",
       "unit_price      0.372942\n",
       "payment         0.275685\n",
       "product_line    0.217674\n",
       "month           0.039390\n",
       "warehouse       0.031947\n",
       "day             0.061492\n",
       "year                 NaN\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(df.corr()[\"total\"].sort_values(ascending=False)) #We look at their correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8baf23",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d243d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=df.drop([\"total\",\"month\",\"warehouse\",\"day\",\"year\"],axis=1),df[[\"total\"]]\n",
    "x=scaler.fit_transform(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2202ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_test(x,y):\n",
    "    L = LinearRegression()\n",
    "    E = ElasticNet()\n",
    "    R = Ridge()\n",
    "    Lass = Lasso()\n",
    "    ETR=ExtraTreeRegressor()\n",
    "    GBR=GradientBoostingRegressor()\n",
    "    XGBC= XGBRegressor()\n",
    "    x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=13)\n",
    "    algos = [L,E,R,Lass,ETR,GBR,XGBC]\n",
    "    algo_names = ['Linear','ElasticNet','Ridge','Lasso','Extra Tree','Gradient Boosting','XGradientBooting']\n",
    "    r_squared = []\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    result = pd.DataFrame(columns = ['R_Squared','RMSE','MAE'],index = algo_names)\n",
    "    for algo in algos:\n",
    "        algo.fit(x_train,y_train)    \n",
    "        r_squared.append(r2_score(y_test,algo.predict(x_test)))\n",
    "        rmse.append(mean_squared_error(y_test, algo.predict(x_test))**.5)\n",
    "        mae.append(mean_absolute_error(y_test, algo.predict(x_test)))\n",
    "    result.R_Squared = r_squared\n",
    "    result.RMSE = rmse\n",
    "    result.MAE= mae\n",
    "    return result.sort_values('R_Squared', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fec3d4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.993412</td>\n",
       "      <td>29.562517</td>\n",
       "      <td>13.045627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGradientBooting</th>\n",
       "      <td>0.987806</td>\n",
       "      <td>40.219284</td>\n",
       "      <td>12.410100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Tree</th>\n",
       "      <td>0.987079</td>\n",
       "      <td>41.401250</td>\n",
       "      <td>16.976450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.859722</td>\n",
       "      <td>136.411966</td>\n",
       "      <td>72.963078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>0.859273</td>\n",
       "      <td>136.630471</td>\n",
       "      <td>75.497196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.859268</td>\n",
       "      <td>136.632623</td>\n",
       "      <td>73.758383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.327339</td>\n",
       "      <td>298.714716</td>\n",
       "      <td>187.590509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   R_Squared        RMSE         MAE\n",
       "Gradient Boosting   0.993412   29.562517   13.045627\n",
       "XGradientBooting    0.987806   40.219284   12.410100\n",
       "Extra Tree          0.987079   41.401250   16.976450\n",
       "Lasso               0.859722  136.411966   72.963078\n",
       "Linear              0.859273  136.630471   75.497196\n",
       "Ridge               0.859268  136.632623   73.758383\n",
       "ElasticNet          0.327339  298.714716  187.590509"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_test(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db2aae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f05225c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(60,activation=\"relu\"))\n",
    "model.add(Dense(60,activation=\"relu\"))\n",
    "model.add(Dense(60,activation=\"relu\"))\n",
    "model.add(Dense(60,activation=\"relu\"))\n",
    "model.add(Dense(60,activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13214cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 3ms/step - loss: 189875.0938 - val_loss: 46262.6836\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 58869.7500 - val_loss: 30124.2129\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39131.4414 - val_loss: 17285.6484\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 25285.1367 - val_loss: 12929.2051\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17089.8066 - val_loss: 8010.4800\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 11642.1904 - val_loss: 3999.7190\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 7866.6968 - val_loss: 2671.1572\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 5059.9126 - val_loss: 1627.8253\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3936.0315 - val_loss: 1552.4944\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2190.5154 - val_loss: 1238.1453\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1617.9656 - val_loss: 831.0977\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1223.4039 - val_loss: 571.5269\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 938.3510 - val_loss: 615.1577\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 815.1031 - val_loss: 455.9010\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 710.9812 - val_loss: 623.7159\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 581.2916 - val_loss: 371.3501\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 561.3116 - val_loss: 405.4256\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 618.2917 - val_loss: 789.4016\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 500.7423 - val_loss: 273.5906\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 398.7136 - val_loss: 301.6664\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 394.6801 - val_loss: 221.8726\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 355.5611 - val_loss: 287.1017\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 366.2882 - val_loss: 229.0110\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 303.4937 - val_loss: 285.8702\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 312.8011 - val_loss: 188.6494\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 287.0002 - val_loss: 248.4876\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 251.0406 - val_loss: 154.9427\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 212.5432 - val_loss: 176.2322\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 200.0529 - val_loss: 165.5036\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 244.5995 - val_loss: 418.6587\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 400.4225 - val_loss: 213.8604\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 178.0513 - val_loss: 134.3569\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 174.4449 - val_loss: 159.1961\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 197.0191 - val_loss: 148.7336\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 154.6097 - val_loss: 129.2446\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 176.1762 - val_loss: 119.6113\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 187.3192 - val_loss: 278.7247\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 128.5205 - val_loss: 144.7687\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 133.9659 - val_loss: 140.9106\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 145.7134 - val_loss: 118.2662\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 110.9312 - val_loss: 243.8961\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 134.6267 - val_loss: 157.9208\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 132.9389 - val_loss: 182.6511\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 109.3546 - val_loss: 135.9327\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 118.0382 - val_loss: 112.2038\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 123.7447 - val_loss: 172.4571\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 261.1295 - val_loss: 108.0750\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 105.9524 - val_loss: 160.1131\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 107.9671 - val_loss: 172.9935\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 176.4963 - val_loss: 100.8478\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 159.1705 - val_loss: 157.3292\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 137.7207 - val_loss: 163.6695\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 117.7600 - val_loss: 110.9995\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 83.9426 - val_loss: 144.5210\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 95.9175 - val_loss: 127.3956\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 161.1415 - val_loss: 311.4161\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 114.2460 - val_loss: 207.7143\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 262.2956 - val_loss: 166.6593\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 132.8241 - val_loss: 105.8559\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 130.8876 - val_loss: 238.4310\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 121.4324 - val_loss: 255.4234\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 63.3632 - val_loss: 99.7686\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 165.4857 - val_loss: 137.1987\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 65.0774 - val_loss: 93.7803\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 94.3806 - val_loss: 119.2656\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 60.6803 - val_loss: 108.2343\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 66.1329 - val_loss: 111.1500\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 148.7858 - val_loss: 152.8139\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 270.6558 - val_loss: 271.8236\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 130.4762 - val_loss: 99.2766\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 53.5578 - val_loss: 99.2226\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 168.8317 - val_loss: 123.8860\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 512.6942 - val_loss: 141.7317\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 63.9627 - val_loss: 86.9879\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 61.1927 - val_loss: 111.3991\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 43.5364 - val_loss: 83.1671\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 58.4569 - val_loss: 93.3662\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 65.1518 - val_loss: 88.4100\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 98.0023 - val_loss: 90.4030\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 45.4706 - val_loss: 112.8780\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 89.0400 - val_loss: 139.7288\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 56.9731 - val_loss: 81.7533\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 61.8643 - val_loss: 91.8217\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 80.8304 - val_loss: 90.6005\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 116.2902 - val_loss: 192.5132\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 88.1894 - val_loss: 85.0133\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 44.7672 - val_loss: 78.9218\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 64.7079 - val_loss: 361.1546\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 53.4100 - val_loss: 77.7179\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 83.0424 - val_loss: 109.0489\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 193.2314 - val_loss: 137.6750\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 481.1996 - val_loss: 336.5249\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 239.5432 - val_loss: 481.3906\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 111.5635 - val_loss: 63.0024\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 32.7096 - val_loss: 72.9399\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 32.8214 - val_loss: 65.5620\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 35.1509 - val_loss: 64.2967\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 38.6005 - val_loss: 71.1970\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 50.1078 - val_loss: 67.5569\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 34.3610 - val_loss: 89.6125\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.0912 - val_loss: 125.9220\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 41.2817 - val_loss: 65.6424\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 147.5368 - val_loss: 232.7046\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 61.4614 - val_loss: 78.3497\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 94.4885 - val_loss: 112.7359\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 51.5997 - val_loss: 64.1895\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 47.2878 - val_loss: 103.2209\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 54.1278 - val_loss: 61.8663\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 51.1235 - val_loss: 96.0583\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 248.1695 - val_loss: 86.1395\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 104.2850 - val_loss: 59.1654\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 38.8188 - val_loss: 56.5842\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 26.1009 - val_loss: 71.0930\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 46.6081 - val_loss: 89.1303\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.3187 - val_loss: 46.1894\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 56.8890 - val_loss: 86.8718\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 78.3085 - val_loss: 55.5076\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 83.8611 - val_loss: 105.0025\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 54.2002 - val_loss: 51.9198\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 83.9551 - val_loss: 159.4105\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 48.8145 - val_loss: 66.1052\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 106.3006 - val_loss: 124.6696\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 57.9984 - val_loss: 68.9341\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39.5352 - val_loss: 59.6483\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 27.5791 - val_loss: 52.0654\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 25.0999 - val_loss: 50.6392\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 160.1479 - val_loss: 243.8884\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 297.7878 - val_loss: 197.5045\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 299.5262 - val_loss: 58.5197\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 54.9660 - val_loss: 191.5858\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 62.5073 - val_loss: 40.4955\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 228.4433 - val_loss: 56.0596\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 65.4524 - val_loss: 67.7948\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39.6910 - val_loss: 41.6152\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 48.0314 - val_loss: 62.3798\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 153.9637 - val_loss: 101.3519\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 46.8077 - val_loss: 63.5091\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 58.5226 - val_loss: 52.6736\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 57.6772 - val_loss: 36.9895\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 38.7123 - val_loss: 37.2356\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 44.4891 - val_loss: 61.2553\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 37.8884 - val_loss: 47.5433\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 57.1777 - val_loss: 36.0166\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.7880 - val_loss: 51.9032\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 43.0292 - val_loss: 36.4895\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 66.2017 - val_loss: 98.2808\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 699.9031 - val_loss: 111.7814\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 40.1335 - val_loss: 41.8065\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 159.5726 - val_loss: 73.8949\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 34.6814 - val_loss: 37.7360\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 19.4926 - val_loss: 43.7070\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 24.2491 - val_loss: 36.1296\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 29.6613 - val_loss: 45.9591\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 65.3030 - val_loss: 69.9264\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 26.8635 - val_loss: 41.7360\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 47.0370 - val_loss: 38.0295\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.2202 - val_loss: 51.9737\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 54.2712 - val_loss: 48.9880\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 638.0349 - val_loss: 3716.3738\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1304.8661 - val_loss: 204.9381\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 154.8501 - val_loss: 127.8288\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 67.9158 - val_loss: 62.9726\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 35.5246 - val_loss: 52.5555\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 29.8518 - val_loss: 50.6256\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 33.5417 - val_loss: 42.6878\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 32.6180 - val_loss: 49.4706\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 26.5316 - val_loss: 46.7736\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 21.5779 - val_loss: 45.6239\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 28.5025 - val_loss: 38.1689\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 28.9999 - val_loss: 45.0981\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 37.2453 - val_loss: 37.8200\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.4597 - val_loss: 37.2277\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 20.2452 - val_loss: 39.8905\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 88.4855 - val_loss: 59.7002\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.1277 - val_loss: 44.2273\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 144.7512 - val_loss: 220.8640\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 211.2491 - val_loss: 93.3963\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 41.6441 - val_loss: 37.7004\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 54.0050 - val_loss: 37.2367\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 45.1283 - val_loss: 34.2876\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 27.1198 - val_loss: 42.2072\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 94.3046 - val_loss: 542.4397\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 571.4690 - val_loss: 199.6703\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 161.0419 - val_loss: 44.3211\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 28.4856 - val_loss: 38.8609\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 21.7583 - val_loss: 35.2243\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 29.4151 - val_loss: 116.1272\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 133.7651 - val_loss: 48.2547\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 44.2344 - val_loss: 42.4897\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 32.2766 - val_loss: 36.9677\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 50.4555 - val_loss: 86.5070\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 129.9486 - val_loss: 84.2260\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 53.0528 - val_loss: 52.3868\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 117.4827 - val_loss: 117.3853\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 74.5259 - val_loss: 71.2452\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 272.7523 - val_loss: 160.4050\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 99.7988 - val_loss: 52.0906\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 37.2243 - val_loss: 62.3385\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 36.2997 - val_loss: 34.4589\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 49.5689 - val_loss: 107.5410\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 26.4431 - val_loss: 46.7875\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 19.0629 - val_loss: 42.0851\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 87.0831 - val_loss: 40.5830\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 72.8104 - val_loss: 49.5251\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 63.7211 - val_loss: 161.9928\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 356.0580 - val_loss: 106.8017\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 108.9643 - val_loss: 113.5962\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 53.4746 - val_loss: 51.4177\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39.7786 - val_loss: 38.3446\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39.1271 - val_loss: 65.1789\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 129.2457 - val_loss: 79.3910\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 53.5543 - val_loss: 32.2512\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 42.3716 - val_loss: 92.2320\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 127.0396 - val_loss: 50.5828\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 198.8837 - val_loss: 73.6824\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 45.0090 - val_loss: 56.4998\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 107.0660 - val_loss: 83.9526\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 316.7904 - val_loss: 195.1699\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 90.7831 - val_loss: 36.5316\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 29.8517 - val_loss: 41.8333\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.9261 - val_loss: 64.4518\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.4255 - val_loss: 34.9153\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 16.2557 - val_loss: 45.2282\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 156.8461 - val_loss: 1096.3511\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 491.4401 - val_loss: 50.7501\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 32.1533 - val_loss: 51.5569\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 34.2515 - val_loss: 64.4822\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 28.7306 - val_loss: 87.9827\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 74.6144 - val_loss: 39.7268\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.5416 - val_loss: 42.1496\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 20.5620 - val_loss: 35.6233\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 28.9455 - val_loss: 53.0427\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 52.5930 - val_loss: 33.1471\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.2965 - val_loss: 36.1648\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 53.3745 - val_loss: 33.7068\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 83.0029 - val_loss: 197.9517\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 95.4405 - val_loss: 281.6148\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 86.3868 - val_loss: 89.3245\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 41.9523 - val_loss: 91.7851\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 412.9347 - val_loss: 184.6107\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 72.5229 - val_loss: 33.2008\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 43.9359 - val_loss: 31.5295\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 36.9135 - val_loss: 90.5293\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 33.5052 - val_loss: 41.5946\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 195.8392 - val_loss: 41.9582\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 52.1653 - val_loss: 76.0169\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 106.3848 - val_loss: 43.1442\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 38.4140 - val_loss: 50.2771\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39.6575 - val_loss: 35.8470\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 134.9733 - val_loss: 84.1120\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 141.4215 - val_loss: 112.1846\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 25.2909 - val_loss: 31.2456\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 15.9626 - val_loss: 26.5979\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 32.9679 - val_loss: 61.1014\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 49.2519 - val_loss: 35.3982\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 86.4883 - val_loss: 112.8908\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 124.5575 - val_loss: 73.3122\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 119.5554 - val_loss: 110.2206\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 211.0699 - val_loss: 29.4623\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 27.1292 - val_loss: 31.6887\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39.5883 - val_loss: 63.7749\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 35.7669 - val_loss: 28.9276\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.1272 - val_loss: 36.6685\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 14.7867 - val_loss: 29.2343\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 19.3038 - val_loss: 34.0616\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.3089 - val_loss: 70.0939\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 55.3780 - val_loss: 55.6147\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 63.0440 - val_loss: 86.9012\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 318.1501 - val_loss: 76.9692\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 56.7445 - val_loss: 73.1639\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 35.6824 - val_loss: 28.4434\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 29.7664 - val_loss: 27.9280\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 18.9015 - val_loss: 32.0436\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 13.5196 - val_loss: 25.4485\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 16.9051 - val_loss: 26.9814\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 24.0793 - val_loss: 23.4244\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 21.4889 - val_loss: 24.0955\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.4513 - val_loss: 55.7238\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 36.2987 - val_loss: 26.1280\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 97.1668 - val_loss: 103.9517\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 195.8947 - val_loss: 29.7872\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 67.0019 - val_loss: 25.7334\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.9112 - val_loss: 40.0300\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 42.4948 - val_loss: 27.2369\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 26.9594 - val_loss: 61.8781\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1078.6067 - val_loss: 174.9583\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 132.0326 - val_loss: 45.7730\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 78.0231 - val_loss: 53.6554\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 100.3361 - val_loss: 359.2964\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 87.3638 - val_loss: 37.6249\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.0188 - val_loss: 35.4864\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 37.5097 - val_loss: 37.9039\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 46.8281 - val_loss: 54.0483\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 93.7779 - val_loss: 40.2332\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 40.3723 - val_loss: 65.1301\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 34.6104 - val_loss: 52.4083\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 44.2695 - val_loss: 42.6677\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 85.8018 - val_loss: 36.6252\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 41.2464 - val_loss: 36.6771\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 30.1080 - val_loss: 54.0944\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 22.3815 - val_loss: 38.4446\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.8669 - val_loss: 30.4430\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 63.5390 - val_loss: 33.0612\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.7948 - val_loss: 71.7789\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 34.4495 - val_loss: 71.0265\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 53.5707 - val_loss: 53.0931\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 58.4376 - val_loss: 70.8125\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 72.9062 - val_loss: 94.2378\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 123.9880 - val_loss: 423.4862\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 160.6176 - val_loss: 65.5908\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 94.1923 - val_loss: 96.9453\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 46.5774 - val_loss: 32.2318\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 141.4548 - val_loss: 55.3759\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 55.8195 - val_loss: 201.6643\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 286.7864 - val_loss: 62.8973\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 96.4329 - val_loss: 35.4650\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 26.8116 - val_loss: 33.2882\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 29.0963 - val_loss: 29.4147\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 21.5078 - val_loss: 44.6807\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 84.4727 - val_loss: 28.5286\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 60.3339 - val_loss: 98.1976\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 32.4659 - val_loss: 25.8570\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 25.6444 - val_loss: 32.9799\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 98.0271 - val_loss: 186.5295\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1329.4175 - val_loss: 716.5648\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 554.0824 - val_loss: 51.1570\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39.3787 - val_loss: 39.5709\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 75.3873 - val_loss: 44.6449\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 21.2421 - val_loss: 35.8465\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.9509 - val_loss: 36.5460\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 33.7133 - val_loss: 29.6633\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.0295 - val_loss: 39.7394\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 14.7784 - val_loss: 27.5316\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.2080 - val_loss: 29.0791\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 13.2093 - val_loss: 28.1487\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 18.4293 - val_loss: 54.0011\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 38.1269 - val_loss: 66.3703\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 22.6274 - val_loss: 33.2483\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 93.3057 - val_loss: 39.6915\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 183.6135 - val_loss: 58.4455\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 75.8578 - val_loss: 205.8832\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 44.9846 - val_loss: 28.3493\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.8446 - val_loss: 28.5843\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 21.7120 - val_loss: 31.0440\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 34.9334 - val_loss: 52.0174\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 68.9391 - val_loss: 58.9900\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 92.1232 - val_loss: 133.1349\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 68.1790 - val_loss: 45.5152\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 135.1366 - val_loss: 57.0579\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 111.0326 - val_loss: 70.5229\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 121.9644 - val_loss: 30.0967\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 14.0862 - val_loss: 27.8514\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 24.7096 - val_loss: 35.8728\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 57.9885 - val_loss: 29.6724\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 34.8128 - val_loss: 29.8915\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.9422 - val_loss: 42.1951\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 28.5068 - val_loss: 27.0861\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 32.9137 - val_loss: 34.0371\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.5433 - val_loss: 139.6281\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 41.3928 - val_loss: 45.3742\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 44.5989 - val_loss: 29.9406\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 287.4732 - val_loss: 4300.1943\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 515.3074 - val_loss: 205.6816\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 70.6061 - val_loss: 27.9155\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 69.9260 - val_loss: 31.4790\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 22.9600 - val_loss: 46.9086\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 77.9112 - val_loss: 27.5768\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 99.4252 - val_loss: 200.7263\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 77.0807 - val_loss: 25.2055\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 48.5368 - val_loss: 105.5790\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 54.3632 - val_loss: 27.9424\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 47.5706 - val_loss: 30.2443\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.2799 - val_loss: 24.3166\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.3368 - val_loss: 25.2594\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 70.0282 - val_loss: 50.2276\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 126.1606 - val_loss: 45.2298\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 52.5169 - val_loss: 59.1624\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 29.2571 - val_loss: 23.1361\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 16.4450 - val_loss: 20.7791\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 71.5872 - val_loss: 46.2461\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 19.4284 - val_loss: 26.8772\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 346.9271 - val_loss: 100.1916\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 98.7459 - val_loss: 27.5401\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 30.0913 - val_loss: 30.2008\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 75.0155 - val_loss: 40.6560\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 79.1579 - val_loss: 32.2475\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 152.4370 - val_loss: 229.8643\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 45.2812 - val_loss: 32.1642\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.5965 - val_loss: 54.9694\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.1923 - val_loss: 23.8874\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 14.8374 - val_loss: 26.6080\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 184.1310 - val_loss: 852.3456\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 169.6383 - val_loss: 31.8213\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 58.9397 - val_loss: 41.8879\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 30.9246 - val_loss: 31.6929\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 35.1291 - val_loss: 89.5183\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 49.1170 - val_loss: 50.1090\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 27.6674 - val_loss: 42.9065\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 27.4107 - val_loss: 136.7557\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 45.5813 - val_loss: 51.3358\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 20.9593 - val_loss: 25.7045\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 24.1522 - val_loss: 102.9569\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.8939 - val_loss: 24.1989\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 27.8369 - val_loss: 90.2784\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 264.7348 - val_loss: 242.0767\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 156.7283 - val_loss: 76.0319\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 34.9219 - val_loss: 57.9221\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 29.0885 - val_loss: 23.2340\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.5818 - val_loss: 28.5056\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.0033 - val_loss: 30.6268\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 19.6109 - val_loss: 28.2725\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 22.0928 - val_loss: 26.3658\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 41.1791 - val_loss: 26.5963\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 43.3448 - val_loss: 97.1479\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 124.1114 - val_loss: 297.8116\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 257.1637 - val_loss: 94.2033\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 93.8257 - val_loss: 85.2442\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 69.4880 - val_loss: 57.0681\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 104.5153 - val_loss: 32.7593\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 54.2969 - val_loss: 27.0121\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 16.1109 - val_loss: 31.5362\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 30.9546 - val_loss: 67.3649\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 44.3675 - val_loss: 28.1648\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 20.3143 - val_loss: 22.2368\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 10.2147 - val_loss: 19.5739\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.8761 - val_loss: 21.3505\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 21.1580 - val_loss: 25.9980\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 13.2278 - val_loss: 22.0759\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 16.6848 - val_loss: 81.2473\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 39.1123 - val_loss: 23.4712\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 984.6008 - val_loss: 1000.3633\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 178.5179 - val_loss: 36.4279\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 33.3837 - val_loss: 37.8375\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 30.2151 - val_loss: 20.4084\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 24.7115 - val_loss: 25.0897\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.6405 - val_loss: 20.3146\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 12.4087 - val_loss: 16.9790\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 24.9784 - val_loss: 18.7105\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 16.7592 - val_loss: 30.5672\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 64.3631 - val_loss: 92.0758\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 45.6411 - val_loss: 50.8811\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 16.2378 - val_loss: 28.0670\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 19.9943 - val_loss: 55.9818\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 22.3684 - val_loss: 24.4961\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 20.3505 - val_loss: 26.4926\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 31.9644 - val_loss: 79.2823\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 82.2079 - val_loss: 55.6354\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 52.0848 - val_loss: 18.5260\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 19.8081 - val_loss: 19.3043\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 8.9838 - val_loss: 21.8941\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 54.7627 - val_loss: 122.2116\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 82.9651 - val_loss: 35.9150\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 62.3501 - val_loss: 62.5827\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 60.0422 - val_loss: 38.7573\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 34.7269 - val_loss: 36.1934\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 70.1611 - val_loss: 25.5485\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 351.3872 - val_loss: 88.4111\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 57.2921 - val_loss: 34.1490\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 67.4026 - val_loss: 25.5229\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.1259 - val_loss: 30.3068\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 30.4847 - val_loss: 25.7906\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 15.7054 - val_loss: 47.9089\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 53.2742 - val_loss: 51.7265\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 52.0346 - val_loss: 27.3593\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 24.3187 - val_loss: 27.3755\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.3033 - val_loss: 19.5182\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 12.3393 - val_loss: 26.7951\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 26.4239 - val_loss: 21.3964\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 30.8606 - val_loss: 66.9261\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 128.6124 - val_loss: 104.5989\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 599.7781 - val_loss: 262.4954\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 103.7264 - val_loss: 50.5997\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 63.2755 - val_loss: 55.2024\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 239.9498 - val_loss: 137.0868\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 61.7409 - val_loss: 27.9041\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 23.4499 - val_loss: 32.1699\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 13.2082 - val_loss: 22.6111\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 32.0778 - val_loss: 39.2139\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 18.6349 - val_loss: 21.2550\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 12.6775 - val_loss: 23.9599\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 38.3692 - val_loss: 26.0089\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 18.1992 - val_loss: 21.1226\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.1899 - val_loss: 46.1395\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 13.6065 - val_loss: 21.1257\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 10.8828 - val_loss: 32.2527\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 33.1060 - val_loss: 32.7677\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 91.1239 - val_loss: 55.3565\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 563.5538 - val_loss: 1373.1425\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 387.6967 - val_loss: 32.1440\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 46.8703 - val_loss: 36.6895\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 21.2245 - val_loss: 45.3053\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 24.0372 - val_loss: 17.7587\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 13.8173 - val_loss: 27.2294\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 13.8245 - val_loss: 43.9105\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 17.1500 - val_loss: 55.1192\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 11.0558 - val_loss: 26.4275\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 122.7794 - val_loss: 530.7561\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 784.1440 - val_loss: 125.0631\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 525.5930 - val_loss: 63.8021\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 77.6122 - val_loss: 49.2472\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (10, 60)                  360       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (10, 60)                  3660      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (10, 60)                  3660      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (10, 60)                  3660      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (10, 60)                  3660      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (10, 1)                   61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,061\n",
      "Trainable params: 15,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=10,epochs=500)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf09496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 831us/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbcb9711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992183336843911"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a465ea7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.017635927850327"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(tahmin,y_test))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e26b631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
